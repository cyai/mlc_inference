## Model: Llama-3-8B-Instruct-q4f16_1-MLC
- **Context Length**: 500 words (system prompt)
- **Latency**:
    ```
    Response Hello, Time: 187.62 ms
    Response I'm g, Time: 44.70 ms
    Response JobTa, Time: 46.78 ms
    Response JobTa, Time: 47.35 ms
    Response I'm a, Time: 46.32 ms
    Response I'm p, Time: 53.83 ms
    Response I'm e, Time: 55.80 ms
    Response I'm g, Time: 62.53 ms
    Response You'r, Time: 67.91 ms
    ```
- **Average Latency**: 68.0933333333 ms
- **Model Config**: Default(prefill_chunk=8192)

## Model: Llama-3-8B-Instruct-q4f16_1-MLC with Prefill Chunk = 2800
- **Context Length**: 500 words (system prompt)
- **Latency**:
    ```
    Response Hello, Time: 194.43 ms
    Response JobTa, Time: 44.56 ms
    Response JobTa, Time: 37.82 ms
    Response I'm a, Time: 47.39 ms
    Response I'm p, Time: 57.31 ms
    Response I cho, Time: 55.06 ms
    Response My SR, Time: 64.04 ms
    Response I'm p, Time: 76.55 ms
    Response I'm p, Time: 69.45 ms
    ```
- **Average Latency**: 71.8455555556 ms

## Model: Llama-3-8B-Instruct-q0f16-MLC 
- **Context Length**: 500 words (system prompt)
- **Latency**:
    ```
    Response Hello, Time: 249.24 ms
    Response I'm a, Time: 73.25 ms
    Response JobTa, Time: 51.33 ms
    Response JobTa, Time: 53.73 ms
    Response As a , Time: 61.44 ms
    Response We do, Time: 60.06 ms
    Response We ch, Time: 62.92 ms
    Response I use, Time: 65.10 ms
    Response As a , Time: 68.18 ms
    ```
- **Average Latency**: 82.8055555556 ms